[
  {
    "objectID": "web.html",
    "href": "web.html",
    "title": "Simple",
    "section": "",
    "text": "import geopandas as gpd\nfrom pathlib import Path\n\n# If you are following along change path \nchange_this = Path('/home/michael/CP/UEFI/vectors')\nbuildings_path = change_this / 'eaton_buildings.geojson'\naoi_path = change_this / 'Eaton_Perimeter_20250121.geojson'\n\n# read buildings and aoi\nbuildings = gpd.read_file(buildings_path)\naoi = gpd.read_file(aoi_path)\n\n\nimport contextily as cx\nimport matplotlib.pyplot as plt\n\nbuildings.plot(color='red', figsize=(9, 9))\n\n\n\n\n\n\n\n\nNot overwhelming. Some buildings, but it would be nice to have a base map.\n\nax = buildings.plot(color='red', figsize=(9, 9))\ncx.add_basemap(ax, crs=buildings.crs)\n\nplt.show()"
  },
  {
    "objectID": "web.html#load-data",
    "href": "web.html#load-data",
    "title": "Simple",
    "section": "",
    "text": "import geopandas as gpd\nfrom pathlib import Path\n\n# If you are following along change path \nchange_this = Path('/home/michael/CP/UEFI/vectors')\nbuildings_path = change_this / 'eaton_buildings.geojson'\naoi_path = change_this / 'Eaton_Perimeter_20250121.geojson'\n\n# read buildings and aoi\nbuildings = gpd.read_file(buildings_path)\naoi = gpd.read_file(aoi_path)\n\n\nimport contextily as cx\nimport matplotlib.pyplot as plt\n\nbuildings.plot(color='red', figsize=(9, 9))\n\n\n\n\n\n\n\n\nNot overwhelming. Some buildings, but it would be nice to have a base map.\n\nax = buildings.plot(color='red', figsize=(9, 9))\ncx.add_basemap(ax, crs=buildings.crs)\n\nplt.show()"
  },
  {
    "objectID": "pdal.html#challenges-working-with-lidar",
    "href": "pdal.html#challenges-working-with-lidar",
    "title": "",
    "section": "Challenges Working with LiDAR",
    "text": "Challenges Working with LiDAR\n\nLarge file sizes\nComplex formats (LAS, LAZ)\nNeed for efficient and reproducible workflows"
  },
  {
    "objectID": "pdal.html#what-can-pdal-do",
    "href": "pdal.html#what-can-pdal-do",
    "title": "",
    "section": "What Can PDAL Do?",
    "text": "What Can PDAL Do?\n\nRead and write point cloud formats (LAS, LAZ,COCPC, E57, etc.)\nFilter, transform, and analyze data\nPipeline-based workflows\nIntegrate with GIS and other tools"
  },
  {
    "objectID": "pdal.html#how-pdal-fits-into-a-workflow",
    "href": "pdal.html#how-pdal-fits-into-a-workflow",
    "title": "",
    "section": "How PDAL Fits into a Workflow",
    "text": "How PDAL Fits into a Workflow\n\nData acquisition –&gt; PDAL processing –&gt; Analysis\nEmphasis on batch processing and automation\nFor example: reprojecting, filtering out noise and classifying ground points in 500 tiles of USGG 3DEP Lidar."
  },
  {
    "objectID": "pdal.html#basic-anatomy-of-pdal",
    "href": "pdal.html#basic-anatomy-of-pdal",
    "title": "",
    "section": "Basic Anatomy of PDAL",
    "text": "Basic Anatomy of PDAL\n\nCommand-line interface (pdal translate, pdal pipeline, pdal info)\nPipelines (JSON files that define processing steps)\nPlugins (filters, readers, writers)\npython-pdal"
  },
  {
    "objectID": "pdal.html#examples",
    "href": "pdal.html#examples",
    "title": "",
    "section": "Examples",
    "text": "Examples\nTry some of the following\npdal info -h\npdal info --summary your.laz\nTo parse that mess you can use jq in bash (on linux or mac). If you want to find the bounds for instance.\npdal info --summary your.laz | jq .summary.bounds\nI think in Powershell that would be\npdal info --summary bird.laz | ConvertFrom-Json | Select-Object -ExpandProperty summary | Select-Object -ExpandProperty bounds\nReproject something …\npdal translate your.laz your_26911.laz filters.reprojection --filters.reprojection.out_srs=\"EPSG:26911\"\nTranslate an entire directory of laz files in parallel using the amazing and nearly infallible GNU Parallel (Linux and Mac only, also possible using Windows Subsystem for Linux (WSL)),\nls your_lidar_directory | parallel 'pdal translate your_lidar_directory/{} your_output_directory/{.}_26911.laz filters.reprojection --filters.reprojection.out_srs=\"EPSG:26911\"'\nI am not going to discuss pipelines at the moment. We will use them shortly in python-pdal though. Its worth noting that using the pdal pipeline utility is often desirable for simplicity (or to us GNU Parallel with it)."
  },
  {
    "objectID": "intro.html#section",
    "href": "intro.html#section",
    "title": "",
    "section": "",
    "text": "Today we will cover a few of the tools we will be using this quarter, which should hopefully be installed.\n+ git\n+ conda\n+ VScode\n+ Rstudio\n+ QGIS\n+ GDAL"
  },
  {
    "objectID": "python_geospatial_basics.html#environment",
    "href": "python_geospatial_basics.html#environment",
    "title": "Python Lectures",
    "section": "Environment",
    "text": "Environment\nBefore we get started we need to set up a Python environment in which to work. We will be using Anaconda for this. It should already be installed on the lab computers. If you are using your own computer\n\nDownload the environment.yml\nIf you are working on a lab computer In the start menu search for Anaconda. Open an Anaconda Powershell. (on linux or mac with Anconda or miniconda or Mamba installed just open a terminal)(If you are installing on your own computer I recommend Mamba)\n\ncd ~\nmkdir geog441\ncd geog441\ncp ~/Downloads/environment.yml .\nconda env create -f environment.yml\nWhat is this environment.yml thing?\nname: geo\nchannels:\n  - defaults\ndependencies: \n  - geopandas\n  - jupyterlab\n  - rioxarray\n  - tabulate\n  - tqdm\nUsing conda env create with the environment yaml creates a new conda environment named geo with the dependencies installed. Next we will activate the geo environment.\nconda activate geo\nNotice that the conda environment shown after the prompt has changed from (base) to (geo).\nIf later you find that you need another package you can add it to the environment (while in the environment) with conda install &lt;whatever_package&gt;.\nMore info on managing conda environments"
  },
  {
    "objectID": "python_geospatial_basics.html#starting-a-jupyter-lab",
    "href": "python_geospatial_basics.html#starting-a-jupyter-lab",
    "title": "Python Lectures",
    "section": "Starting a Jupyter Lab",
    "text": "Starting a Jupyter Lab\njupyter lab\nThis will open a new jupyter lab in your browser."
  },
  {
    "objectID": "python_geospatial_basics.html#using-vscode",
    "href": "python_geospatial_basics.html#using-vscode",
    "title": "Python Lectures",
    "section": "Using VScode",
    "text": "Using VScode\nRunning Jupyter in VScode offers some advantages (in my opinion). To do this you need to install the jupyter extension and the Python Extension. Then when you open a file with a .ipynb extension it will be treated as a Jupyter notebook."
  },
  {
    "objectID": "python_geospatial_basics.html#basic-python-data-types",
    "href": "python_geospatial_basics.html#basic-python-data-types",
    "title": "Python Lectures",
    "section": "Basic Python data types",
    "text": "Basic Python data types\n\n\n\n\n\n\n\nType\nExample(s)\n\n\n\n\nString\n'Dude!'\n\n\nFloat\n1.2\n\n\nInt\n3\n\n\nTuple\n('x', 'y')(1, 2)('x', 3.2)\n\n\nList\n['x', 'y'][1, 2]Possible but bad –&gt; ['x', 3.2]\n\n\nDict\n{'dogs': 26, 'cats', 100}\n\n\netc…\nthere are others"
  },
  {
    "objectID": "python_geospatial_basics.html#basic-numbers",
    "href": "python_geospatial_basics.html#basic-numbers",
    "title": "Python Lectures",
    "section": "Basic Numbers",
    "text": "Basic Numbers\nFloats and Ints don’t do anything all that surprising\n\n\na = 2 + 2\nb = 2.0 + 2.0\nc = a + b\n\n\nprint(f'a is an {type(a)}')\nprint(f'b is a {type(b)}')\nprint(f'c is a {type(c)}')\nprint(f'a / b is {a / b}')\nprint(f'5 / 4 is {5 / 4}')\nprint(f'but 5 // 4 is {5 // 4}')\nprint(f'and 5 % 4 is {5 % 4}')\n\n\na is an &lt;class 'int'&gt;\nb is a &lt;class 'float'&gt;\nc is a &lt;class 'float'&gt;\na / b is 1.0\n5 / 4 is 1.25\nbut 5 // 4 is 1\nand 5 % 4 is 1"
  },
  {
    "objectID": "python_geospatial_basics.html#exercise---basic-numbers",
    "href": "python_geospatial_basics.html#exercise---basic-numbers",
    "title": "Python Lectures",
    "section": "Exercise - Basic Numbers",
    "text": "Exercise - Basic Numbers\nTry the following, print the results, see what they do.\n\n\na = 5 // 4\nb = 5 % 4\nc = a + b"
  },
  {
    "objectID": "python_geospatial_basics.html#sequences",
    "href": "python_geospatial_basics.html#sequences",
    "title": "Python Lectures",
    "section": "Sequences",
    "text": "Sequences\nLists, tuples, and strings ae all sequences\n\n\n# a list\na_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# a tuple\na_tup = (1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n# a string\na_str = 'Wil je graag een neushorn?'\n\n# access by index\na = a_list[0]\nb = a_list[-1]\nc = a_list[4]\nprint(f'by index:\\n 0 --&gt; {a},\\n-1 --&gt; {b},\\n 4 --&gt; {c}')\n\n# works fro strings to\nprint('string item at 4 --&gt; ', a_str[4])\n\n# you can slice a list or tuple(remember 0 indexed)\nprint('\\nslices:')\nprint(a_list[2:5])\nprint(a_list[8:])\nprint(a_tup[2:5])\nprint(a_str[-9:])\n\n\nby index:\n 0 --&gt; 1,\n-1 --&gt; 9,\n 4 --&gt; 5\nstring item at 4 --&gt;  j\n\nslices:\n[3, 4, 5]\n[9]\n(3, 4, 5)\nneushorn?\n\n\nSlicing\nSequences tutorial\nSequence tutorial as video"
  },
  {
    "objectID": "python_geospatial_basics.html#exercise---lists-and-tuples",
    "href": "python_geospatial_basics.html#exercise---lists-and-tuples",
    "title": "Python Lectures",
    "section": "Exercise - Lists and Tuples",
    "text": "Exercise - Lists and Tuples\nThe key between lists and tuples is that tuples are immutable. Try assigning a value to both of the following.\n\n\n# a list\na_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# a tuple\na_tup = (1, 2, 3, 4, 5, 6, 7, 8, 9)"
  },
  {
    "objectID": "python_geospatial_basics.html#dictionaries",
    "href": "python_geospatial_basics.html#dictionaries",
    "title": "Python Lectures",
    "section": "Dictionaries",
    "text": "Dictionaries\n\n\npets = {'honden': 26, 'katten': 100}\n\nfor key, val in pets.items():\n  print(f'{val} {key}')\n\nprint(f'{pets[\"honden\"] + pets[\"katten\"]} huisdieren')\n\n\n26 honden\n100 katten\n126 huisdieren\n\n\nMore on dictionaries"
  },
  {
    "objectID": "python_geospatial_basics.html#iterating",
    "href": "python_geospatial_basics.html#iterating",
    "title": "Python Lectures",
    "section": "Iterating",
    "text": "Iterating\n\n\na = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# use a loop to append squared values to new lists\nb = []\nfor n in a:\n  b.append(n**2)\n\n# or, better, use a comprehension\nc = [n**2 for n in a]\n\nprint(b)\nprint('is the same as')\nprint(c)\n\n\n[1, 4, 9, 16, 25, 36, 49, 64, 81]\nis the same as\n[1, 4, 9, 16, 25, 36, 49, 64, 81]"
  },
  {
    "objectID": "python_geospatial_basics.html#exercise---iterating",
    "href": "python_geospatial_basics.html#exercise---iterating",
    "title": "Python Lectures",
    "section": "Exercise - Iterating",
    "text": "Exercise - Iterating\nYou can nest loops.\n\n\nnumbers = []\nfor i in range(3):\n  for j in range(3):\n    numbers.append((i, j))\n\nnumbers\n\n\n[(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)]\n\n\n\nRecreate the above with a list comprehension.\nreplace the square brackets in this list comprehension, = [n**2 for n in a], with parenthesis.\nCan you create a dictionary with a comprehension."
  },
  {
    "objectID": "python_geospatial_basics.html#functions",
    "href": "python_geospatial_basics.html#functions",
    "title": "Python Lectures",
    "section": "Functions",
    "text": "Functions\n\nDefined with def\nCan take arguments\ncan return something\nhave there own scope\n\n\n\nimport numpy as np\n\ndef root_mean_square(list_of_numbers):\n  rms = np.sqrt(\n    np.array([n**2 for n in list_of_numbers]).sum() /\n    len(list_of_numbers)\n    )\n\n  return rms\n\nl = [1.2, 3.3, 1.4, 1.4, 4.2]\nrms = root_mean_square(l)\n\nprint(rms)\n\n\n2.6034592372457075\n\n\nThey do not have to have arguments or return stuff.\n\n\ndef complain():\n  print('This is boring!\\nwhen will we get to the GIS stuff.\\n\\U0001F620\\U0001F620\\U0001F620\\n\\nSoon! Bear with me.')\n\ncomplain()\n\n\nThis is boring!\nwhen will we get to the GIS stuff.\n😠😠😠\n\nSoon! Bear with me.\n\n\nPython is an object oriented programming language. Everything that you can assign to a variable (which is almost everything) can be though of as an object, for example, built in functions are objects.\n\n\nzzz = print\nzzz('toenails')\n\n\ntoenails\n\n\nMany objects have built in functions as an attribute, these are called methods. For instance, strings have a method called split (they have many other methods as well).\n\n\ns = 'hyphens-are-everywhere-they-haunt-me-in-my-dreams'\ns.split('-')\n\n\n['hyphens', 'are', 'everywhere', 'they', 'haunt', 'me', 'in', 'my', 'dreams']\n\n\nWe will encounter heaps of methods later."
  },
  {
    "objectID": "python_geospatial_basics.html#exercise---functions",
    "href": "python_geospatial_basics.html#exercise---functions",
    "title": "Python Lectures",
    "section": "Exercise - Functions",
    "text": "Exercise - Functions\nUse a function and a list comprehension to reproduce the results of the for loop below:\n\n\nl = [(4, 3, 2), (2, 2, 2), (1, 2, 3)]\n\nresults = []\n\nfor t in l:\n  results.append(\n    t[0] + t[1] - t[2] +\n    (t[0] * t[1] + t[2])**t[1] /\n    (t[1]**2 * 5**t[0])\n  )\n\nresults\n\n\n[5.487822222222222, 2.36, 1.25]\n\n\nTake some time to contemplate, what is this?\n\n\nimport numpy as np\n\nnested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\nnp.array(nested_list)\n\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\nBTW, you can import a library as anything you want\n\n\nimport numpy as frogz_on_crack\n\nfrogz_on_crack.array([1, 2, 3]) \n\n\narray([1, 2, 3])\n\n\nWhy would one avoid doing this kind of thing?\nYou can also dump all of the objects from a module into the main namespace\n\n\n# from numpy import everything\nfrom numpy import *\n\narray([1, 2, 3 ])\n\n\narray([1, 2, 3])\n\n\nWhy is this a bad practice? What Is a namespace\n\n\nx = 'I love \\U0001F30D'\n\ndef print_wrapper():\n    print(x)\n\ndef print_poo():\n    x = 'This is the value of x within the function'\n    print(x)\n\nprint_wrapper()\nprint_poo()\n\nprint(x)\n\n\nI love 🌍\nThis is the value of x within the function\nI love 🌍"
  },
  {
    "objectID": "python_geospatial_basics.html#pandas-dataframe",
    "href": "python_geospatial_basics.html#pandas-dataframe",
    "title": "Python Lectures",
    "section": "Pandas DataFrame",
    "text": "Pandas DataFrame\nDataFrames hold tabular data. Here we will read a csv file as a DataFrame and mess with it.\n\nThis cell just downloads the file from a url. Take a few minutes and see if you can change it to be generally useful by allowing the url and save location to be specified as arguments. Hint, you need to change very little, and you don’t really need to know how the function works in any detail.\n\n\n\nimport requests\nfrom pathlib import Path\n\ndef get_NZ_file():\n  '''\n  A purposefully bad function to download one specific file.\n  '''\n  # url to Dec 2024 NZ GH emissions by industry (long url!)\n  url = 'https://www.stats.govt.nz/assets/Uploads/Greenhouse-gas-emissions-industry-and-household/Greenhouse-gas-emissions-industry-and-household-December-2024-quarter/Download-data/greenhouse-gas-emissions-industry-and-household-december-2024-quarter.csv'\n  # make a dir for data, if does not exist\n  save_dir = Path.cwd() / 'data'\n  save_dir.mkdir(exist_ok=True)\n  # get file name\n  basename = url.split('/')[-1]\n  # and a directory to save to \n  save_path = save_dir / basename\n\n  try:\n      response = requests.get(url, stream=True)\n      # raise HTTPError for bad responses (4xx or 5xx)\n      response.raise_for_status() \n      with open(save_path, 'wb') as file:\n        for chunk in response.iter_content(chunk_size=8192):\n          file.write(chunk)\n      print(f\"File downloaded successfully to {save_path}\")\n\n  except requests.exceptions.RequestException as e:\n    print(f'An error occurred: {e}')\n  except Exception as e:\n    print(f'An unexpected error occurred: {e}')\n\n  return save_path\n\nfile_path = get_NZ_file()\n\n\nFile downloaded successfully to /home/michael/CP/geog441/data/greenhouse-gas-emissions-industry-and-household-december-2024-quarter.csv\n\n\n\nRead the csv, and look at the head (first few rows). Notice that there are column names, and on the left side there is a numerical index.\n\n\n\nimport pandas as pd\n\ndf = pd.read_csv(file_path)\ndf.head()\n\n\n\n\n\n\n\n\n\nAnzsic\nAnzsic_descriptor\nGas\nPeriod\nData_value\nVariable\nUnits\nMagnitude\n\n\n\n\n0\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2010.03\n10875\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n1\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2010.06\n11003\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n2\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2010.09\n10993\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n3\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2010.12\n10914\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n4\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2011.03\n11014\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n\n\n\n\n\nWe can also see the last few rows if we want.\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n\nAnzsic\nAnzsic_descriptor\nGas\nPeriod\nData_value\nVariable\nUnits\nMagnitude\n\n\n\n\n4795\nZZZ\nTotal\nNitrous oxide\n2023.12\n1708\nActual\nKilotonnes\nCarbon dioxide equivalents\n\n\n4796\nZZZ\nTotal\nNitrous oxide\n2024.03\n1615\nActual\nKilotonnes\nCarbon dioxide equivalents\n\n\n4797\nZZZ\nTotal\nNitrous oxide\n2024.06\n1482\nActual\nKilotonnes\nCarbon dioxide equivalents\n\n\n4798\nZZZ\nTotal\nNitrous oxide\n2024.09\n1652\nActual\nKilotonnes\nCarbon dioxide equivalents\n\n\n4799\nZZZ\nTotal\nNitrous oxide\n2024.12\n1662\nActual\nKilotonnes\nCarbon dioxide equivalents\n\n\n\n\n\n\n\nOr we can slice from the middle using index slicing, just like with a list.\n\n\ndf[100:105]\n\n\n\n\n\n\n\n\n\nAnzsic\nAnzsic_descriptor\nGas\nPeriod\nData_value\nVariable\nUnits\nMagnitude\n\n\n\n\n100\nBB1\nMining\nCarbon dioxide equivalents\n2020.03\n307\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n101\nBB1\nMining\nCarbon dioxide equivalents\n2020.06\n256\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n102\nBB1\nMining\nCarbon dioxide equivalents\n2020.09\n280\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n103\nBB1\nMining\nCarbon dioxide equivalents\n2020.12\n271\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n104\nBB1\nMining\nCarbon dioxide equivalents\n2021.03\n276\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n\n\n\n\n\nThere are many other ways to select from Pandas DataFrames.\nThe Period column gives dates, but they are in a format that will be interpreted as floats (e.g. 20007.08). Here we change them to datetimes and use them to set the index, giving us a DateTime index.\nEarlier we mentioned methods, and we saw that strings have method split() which splits the string. Columns in Pandas that are of the type str, that is to say string, have all of the same methods under an attribute called str.\nThis cell uses many methods strung together to change the Period column to DateTime format and set the index.\n\n\ndf.index = pd.to_datetime(\n  df.Period.astype('str').str.split('.').str.join('-')\n)\n\ndf.head()\n\n\n\n\n\n\n\n\n\nAnzsic\nAnzsic_descriptor\nGas\nPeriod\nData_value\nVariable\nUnits\nMagnitude\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n\n\n\n2010-03-01\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2010.03\n10875\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n2010-06-01\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2010.06\n11003\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n2010-09-01\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2010.09\n10993\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n2010-12-01\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2010.12\n10914\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n2011-03-01\nAAZ\nAgriculture, forestry, fishing\nCarbon dioxide equivalents\n2011.03\n11014\nSeasonally adjusted\nKilotonnes\nCarbon dioxide equivalents\n\n\n\n\n\n\n\nSee what gasses are measured by looking at unique values in the Gas column.\n\n\ndf.Gas.unique()\n\n\narray(['Carbon dioxide equivalents', 'Methane', 'Carbon dioxide',\n       'Fluorinated gases', 'Nitrous oxide'], dtype=object)\n\n\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1)\n\ndf[(df.index.month == 6) &\n  (df.Gas == 'Nitrous oxide') &\n  (df.Anzsic == 'ZZZ')\n].plot.scatter('Period', 'Data_value', ax=ax)\nax.set_title('NZ June Nitrous Oxide Emissions')\nax.set_ylabel('Kilotonnes')\nax.set_xlabel('Year')\n\n\nText(0.5, 0, 'Year')"
  },
  {
    "objectID": "python_geospatial_basics.html#pandas-dataframe-cont.",
    "href": "python_geospatial_basics.html#pandas-dataframe-cont.",
    "title": "Python Lectures",
    "section": "Pandas DataFrame Cont.",
    "text": "Pandas DataFrame Cont.\nThere is a lot more to know about Pandas DataFrames. This is enough for us to move on to GeoPandas. I encourage you to learn more about Pandas as an exercise."
  },
  {
    "objectID": "python_geospatial_basics.html#geopandas",
    "href": "python_geospatial_basics.html#geopandas",
    "title": "Python Lectures",
    "section": "Geopandas",
    "text": "Geopandas"
  },
  {
    "objectID": "python_geospatial_basics.html#vector-data",
    "href": "python_geospatial_basics.html#vector-data",
    "title": "Python Lectures",
    "section": "Vector Data",
    "text": "Vector Data\n\nMost often we will interact with vector data using GeoPandas\n\nGeoPandas is an extension of Pandas.\nIt uses Fiona, which in-turn relies on GDAL and OGR, to read and write.\nVector data is handled by the Shapely module, which relies on GEOS.\nGEOS implements the OGC Simple Features geometry\n\nProjections are managed by pyproj which is built upon PROJ"
  },
  {
    "objectID": "python_geospatial_basics.html#shapely",
    "href": "python_geospatial_basics.html#shapely",
    "title": "Python Lectures",
    "section": "Shapely",
    "text": "Shapely\n\nShapely Geometric Objects consist of coordinate tuples:\n\nPoint - (x, y) or three dimensional (x, y, z), e.g. Point(5.2, 52.1)\nLineString - List if coordinates of vertices, e.g. LineString([(0, 0), (1, 2)])\nPolygon - Basically a closed linestring, e.g. Polygon(((0., 0.), (0., 1.), (1., 1.), (1., 0.), (0., 0.)))\nNotice that the first and last coord of the Polygon are the same.\nMore on Shapely geometries"
  },
  {
    "objectID": "python_geospatial_basics.html#polygon",
    "href": "python_geospatial_basics.html#polygon",
    "title": "Python Lectures",
    "section": "Polygon",
    "text": "Polygon\n\n\nfrom shapely import Polygon\n\ncoords = ((0., 0.), (0., 2.), (1., 1.), (1., 0.), (0., 0.))\np = Polygon(coords)\n\nc = p.exterior.coords\n\nprint(c[0] == c[-1])\np\n\n\nTrue"
  },
  {
    "objectID": "python_geospatial_basics.html#reading-files",
    "href": "python_geospatial_basics.html#reading-files",
    "title": "Python Lectures",
    "section": "Reading Files",
    "text": "Reading Files\nHere we will read a geojson using the read_file method.\n\n\nfrom pathlib import Path\nimport geopandas as gpd\n\n# path to data\ndata_dir = Path('data')\ngeojson = data_dir / 'upper_santa_rita_creek.geojson'\n\n# open the geojson\ngdf = gpd.read_file(geojson)\n\ngdf\n\n\n\n\n\n\n\n\n\nid\ngeometry\n\n\n\n\n0\nglobalwatershedpoint\nPOINT (-120.80331 35.52537)\n\n\n1\nglobalwatershed\nPOLYGON ((-120.81096 35.50944, -120.81161 35.5...\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport contextily as cx\n\nfig, ax = plt.subplots(figsize=(10, 10))\ngdf.to_crs(epsg=3857).plot(\n  edgecolor='r',\n  ax=ax,\n  facecolor='none')\ncx.add_basemap(\n  ax=ax,\n  source=cx.providers.USGS.USImageryTopo\n)\n\n\n\n\n\n\n\n\n\n\n\nimport geodatasets\nchicago = gpd.read_file(geodatasets.get_path('geoda.chicago_commpop'))\nchicago.head()\n\n\n\n\n\n\n\n\n\ncommunity\nNID\nPOP2010\nPOP2000\nPOPCH\nPOPPERCH\npopplus\npopneg\ngeometry\n\n\n\n\n0\nDOUGLAS\n35\n18238\n26470\n-8232\n-31.099358\n0\n1\nMULTIPOLYGON (((-87.60914 41.84469, -87.60915 ...\n\n\n1\nOAKLAND\n36\n5918\n6110\n-192\n-3.142390\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59231 ...\n\n\n2\nFULLER PARK\n37\n2876\n3420\n-544\n-15.906433\n0\n1\nMULTIPOLYGON (((-87.6288 41.80189, -87.62879 4...\n\n\n3\nGRAND BOULEVARD\n38\n21929\n28006\n-6077\n-21.698922\n0\n1\nMULTIPOLYGON (((-87.60671 41.81681, -87.6067 4...\n\n\n4\nKENWOOD\n39\n17841\n18363\n-522\n-2.842673\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59215 ...\n\n\n\n\n\n\n\nPlot Cloropleth\n\n\nchicago.plot(column=\"POP2010\")\n\n\n\n\n\n\n\n\n\nThe Chicago example is taken from GeoPandas Mapping and plotting tools tutorial, which you should take a look at."
  },
  {
    "objectID": "Xarray.html",
    "href": "Xarray.html",
    "title": "Xarray",
    "section": "",
    "text": "In this tutorial we will be looking at sea surface temperatures using Community Earth System Model 2 (CESM2) data. This tutorial borrows heavily from this tutorial by Computational Tools in Climate Science. That tutorial has much more information about climatology, the focus here is using Xarray for data cubes.\nThis is gridded climate data given in lat, lon coordinates. In the rioXarray tutorials we will learn to deal with projections etc…\nFirst import libraries and download dataset.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\nfrom pythia_datasets import DATASETS\nimport matplotlib.pyplot as plt\n\n\nfilepath = DATASETS.fetch('CESM2_sst_data.nc')\n\nOpen the dataset and inspect. It is an Xarray Dataset. It has coordinates lat, lon, and time. It has corresponding indices It has spatial and time coordinates, hence we call it a spatio-temporal dataset.\n\nds = xr.open_dataset(filepath)\nds\n\n/home/michael/miniconda3/envs/geo3/lib/python3.12/site-packages/xarray/conventions.py:204: SerializationWarning: variable 'tos' has multiple fill values {np.float32(1e+20), np.float64(1e+20)} defined, decoding all values to NaN.\n  var = coder.decode(var, name=name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 47MB\nDimensions:    (time: 180, d2: 2, lat: 180, lon: 360)\nCoordinates:\n  * time       (time) object 1kB 2000-01-15 12:00:00 ... 2014-12-15 12:00:00\n  * lat        (lat) float64 1kB -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n  * lon        (lon) float64 3kB 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5\nDimensions without coordinates: d2\nData variables:\n    time_bnds  (time, d2) object 3kB ...\n    lat_bnds   (lat, d2) float64 3kB ...\n    lon_bnds   (lon, d2) float64 6kB ...\n    tos        (time, lat, lon) float32 47MB ...\nAttributes: (12/45)\n    Conventions:            CF-1.7 CMIP-6.2\n    activity_id:            CMIP\n    branch_method:          standard\n    branch_time_in_child:   674885.0\n    branch_time_in_parent:  219000.0\n    case_id:                972\n    ...                     ...\n    sub_experiment_id:      none\n    table_id:               Omon\n    tracking_id:            hdl:21.14100/2975ffd3-1d7b-47e3-961a-33f212ea4eb2\n    variable_id:            tos\n    variant_info:           CMIP6 20th century experiments (1850-2014) with C...\n    variant_label:          r11i1p1f1xarray.DatasetDimensions:time: 180d2: 2lat: 180lon: 360Coordinates: (3)time(time)object2000-01-15 12:00:00 ... 2014-12-...axis :Tbounds :time_bndsstandard_name :timetitle :timetype :doublearray([cftime.DatetimeNoLeap(2000, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 12, 15, 12, 0, 0, 0, has_year_zero=True)],\n      dtype=object)lat(lat)float64-89.5 -88.5 -87.5 ... 88.5 89.5axis :Ybounds :lat_bndslong_name :latitudestandard_name :latitudeunits :degrees_northarray([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       -79.5, -78.5, -77.5, -76.5, -75.5, -74.5, -73.5, -72.5, -71.5, -70.5,\n       -69.5, -68.5, -67.5, -66.5, -65.5, -64.5, -63.5, -62.5, -61.5, -60.5,\n       -59.5, -58.5, -57.5, -56.5, -55.5, -54.5, -53.5, -52.5, -51.5, -50.5,\n       -49.5, -48.5, -47.5, -46.5, -45.5, -44.5, -43.5, -42.5, -41.5, -40.5,\n       -39.5, -38.5, -37.5, -36.5, -35.5, -34.5, -33.5, -32.5, -31.5, -30.5,\n       -29.5, -28.5, -27.5, -26.5, -25.5, -24.5, -23.5, -22.5, -21.5, -20.5,\n       -19.5, -18.5, -17.5, -16.5, -15.5, -14.5, -13.5, -12.5, -11.5, -10.5,\n        -9.5,  -8.5,  -7.5,  -6.5,  -5.5,  -4.5,  -3.5,  -2.5,  -1.5,  -0.5,\n         0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n        10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,  19.5,\n        20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,  28.5,  29.5,\n        30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,  37.5,  38.5,  39.5,\n        40.5,  41.5,  42.5,  43.5,  44.5,  45.5,  46.5,  47.5,  48.5,  49.5,\n        50.5,  51.5,  52.5,  53.5,  54.5,  55.5,  56.5,  57.5,  58.5,  59.5,\n        60.5,  61.5,  62.5,  63.5,  64.5,  65.5,  66.5,  67.5,  68.5,  69.5,\n        70.5,  71.5,  72.5,  73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5])lon(lon)float640.5 1.5 2.5 ... 357.5 358.5 359.5axis :Xbounds :lon_bndslong_name :longitudestandard_name :longitudeunits :degrees_eastarray([  0.5,   1.5,   2.5, ..., 357.5, 358.5, 359.5], shape=(360,))Data variables: (4)time_bnds(time, d2)object...[360 values with dtype=object]lat_bnds(lat, d2)float64...long_name :latitude boundsunits :degrees_north[360 values with dtype=float64]lon_bnds(lon, d2)float64...long_name :longitude boundsunits :degrees_east[720 values with dtype=float64]tos(time, lat, lon)float32...cell_measures :area: areacellocell_methods :area: mean where sea time: meancomment :Model data on the 1x1 grid includes values in all cells for which ocean cells on the native grid cover more than 52.5 percent of the 1x1 grid cell. This 52.5 percent cutoff was chosen to produce ocean surface area on the 1x1 grid as close as possible to ocean surface area on the native grid, while not introducing fractional cell coverage.description :This may differ from \"surface temperature\" in regions of sea ice or floating ice shelves. For models using conservative temperature as the prognostic field, they should report the top ocean layer as surface potential temperature, which is the same as surface in situ temperature.frequency :monid :toslong_name :Sea Surface TemperaturemipTable :Omonout_name :tosprov :Omon ((isd.003))realm :oceanstandard_name :sea_surface_temperaturetime :timetime_label :time-meantime_title :Temporal meantitle :Sea Surface Temperaturetype :realunits :degCvariable_id :tos[11664000 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(CFTimeIndex([2000-01-15 12:00:00, 2000-02-14 00:00:00, 2000-03-15 12:00:00,\n             2000-04-15 00:00:00, 2000-05-15 12:00:00, 2000-06-15 00:00:00,\n             2000-07-15 12:00:00, 2000-08-15 12:00:00, 2000-09-15 00:00:00,\n             2000-10-15 12:00:00,\n             ...\n             2014-03-15 12:00:00, 2014-04-15 00:00:00, 2014-05-15 12:00:00,\n             2014-06-15 00:00:00, 2014-07-15 12:00:00, 2014-08-15 12:00:00,\n             2014-09-15 00:00:00, 2014-10-15 12:00:00, 2014-11-15 00:00:00,\n             2014-12-15 12:00:00],\n            dtype='object', length=180, calendar='noleap', freq=None))latPandasIndexPandasIndex(Index([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       ...\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5],\n      dtype='float64', name='lat', length=180))lonPandasIndexPandasIndex(Index([  0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n       ...\n       350.5, 351.5, 352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5],\n      dtype='float64', name='lon', length=360))Attributes: (45)Conventions :CF-1.7 CMIP-6.2activity_id :CMIPbranch_method :standardbranch_time_in_child :674885.0branch_time_in_parent :219000.0case_id :972cesm_casename :b.e21.BHIST.f09_g17.CMIP6-historical.011contact :cesm_cmip6@ucar.educreation_date :2019-04-02T04:44:58Zdata_specs_version :01.00.29experiment :Simulation of recent past (1850 to 2014). Impose changing conditions (consistent with observations). Should be initialised from a point early enough in the pre-industrial control run to ensure that the end of all the perturbed runs branching from the end of this historical run end before the end of the control. Only one ensemble member is requested but modelling groups are strongly encouraged to submit at least three ensemble members of their CMIP historical simulation. experiment_id :historicalexternal_variables :areacelloforcing_index :1frequency :monfurther_info_url :https://furtherinfo.es-doc.org/CMIP6.NCAR.CESM2.historical.none.r11i1p1f1grid :ocean data regridded from native gx1v7 displaced pole grid (384x320 latxlon) to 180x360 latxlon using conservative regriddinggrid_label :grinitialization_index :1institution :National Center for Atmospheric Research, Climate and Global Dynamics Laboratory, 1850 Table Mesa Drive, Boulder, CO 80305, USAinstitution_id :NCARlicense :CMIP6 model data produced by &lt;The National Center for Atmospheric Research&gt; is licensed under a Creative Commons Attribution-[]ShareAlike 4.0 International License (https://creativecommons.org/licenses/). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file)[]. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.mip_era :CMIP6model_doi_url :https://doi.org/10.5065/D67H1H0Vnominal_resolution :1x1 degreeparent_activity_id :CMIPparent_experiment_id :piControlparent_mip_era :CMIP6parent_source_id :CESM2parent_time_units :days since 0001-01-01 00:00:00parent_variant_label :r1i1p1f1physics_index :1product :model-outputrealization_index :11realm :oceansource :CESM2 (2017): atmosphere: CAM6 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); ocean: POP2 (320x384 longitude/latitude; 60 levels; top grid cell 0-10 m); sea_ice: CICE5.1 (same grid as ocean); land: CLM5 0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); aerosol: MAM4 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); atmoschem: MAM4 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); landIce: CISM2.1; ocnBgchem: MARBL (320x384 longitude/latitude; 60 levels; top grid cell 0-10 m)source_id :CESM2source_type :AOGCM BGCsub_experiment :nonesub_experiment_id :nonetable_id :Omontracking_id :hdl:21.14100/2975ffd3-1d7b-47e3-961a-33f212ea4eb2variable_id :tosvariant_info :CMIP6 20th century experiments (1850-2014) with CAM6, interactive land (CLM5), coupled ocean (POP2) with biogeochemistry (MARBL), interactive sea ice (CICE5.1), and non-evolving land ice (CISM2.1)variant_label :r11i1p1f1\n\n\nYou can subset the data along an axis with slicing (here we explicitly create a slice object)\n\nds.sel(\n    time=slice('2004-01-01', '2004-12-31')\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3MB\nDimensions:    (time: 12, d2: 2, lat: 180, lon: 360)\nCoordinates:\n  * time       (time) object 96B 2004-01-15 12:00:00 ... 2004-12-15 12:00:00\n  * lat        (lat) float64 1kB -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n  * lon        (lon) float64 3kB 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5\nDimensions without coordinates: d2\nData variables:\n    time_bnds  (time, d2) object 192B ...\n    lat_bnds   (lat, d2) float64 3kB ...\n    lon_bnds   (lon, d2) float64 6kB ...\n    tos        (time, lat, lon) float32 3MB ...\nAttributes: (12/45)\n    Conventions:            CF-1.7 CMIP-6.2\n    activity_id:            CMIP\n    branch_method:          standard\n    branch_time_in_child:   674885.0\n    branch_time_in_parent:  219000.0\n    case_id:                972\n    ...                     ...\n    sub_experiment_id:      none\n    table_id:               Omon\n    tracking_id:            hdl:21.14100/2975ffd3-1d7b-47e3-961a-33f212ea4eb2\n    variable_id:            tos\n    variant_info:           CMIP6 20th century experiments (1850-2014) with C...\n    variant_label:          r11i1p1f1xarray.DatasetDimensions:time: 12d2: 2lat: 180lon: 360Coordinates: (3)time(time)object2004-01-15 12:00:00 ... 2004-12-...axis :Tbounds :time_bndsstandard_name :timetitle :timetype :doublearray([cftime.DatetimeNoLeap(2004, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 12, 15, 12, 0, 0, 0, has_year_zero=True)],\n      dtype=object)lat(lat)float64-89.5 -88.5 -87.5 ... 88.5 89.5axis :Ybounds :lat_bndslong_name :latitudestandard_name :latitudeunits :degrees_northarray([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       -79.5, -78.5, -77.5, -76.5, -75.5, -74.5, -73.5, -72.5, -71.5, -70.5,\n       -69.5, -68.5, -67.5, -66.5, -65.5, -64.5, -63.5, -62.5, -61.5, -60.5,\n       -59.5, -58.5, -57.5, -56.5, -55.5, -54.5, -53.5, -52.5, -51.5, -50.5,\n       -49.5, -48.5, -47.5, -46.5, -45.5, -44.5, -43.5, -42.5, -41.5, -40.5,\n       -39.5, -38.5, -37.5, -36.5, -35.5, -34.5, -33.5, -32.5, -31.5, -30.5,\n       -29.5, -28.5, -27.5, -26.5, -25.5, -24.5, -23.5, -22.5, -21.5, -20.5,\n       -19.5, -18.5, -17.5, -16.5, -15.5, -14.5, -13.5, -12.5, -11.5, -10.5,\n        -9.5,  -8.5,  -7.5,  -6.5,  -5.5,  -4.5,  -3.5,  -2.5,  -1.5,  -0.5,\n         0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n        10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,  19.5,\n        20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,  28.5,  29.5,\n        30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,  37.5,  38.5,  39.5,\n        40.5,  41.5,  42.5,  43.5,  44.5,  45.5,  46.5,  47.5,  48.5,  49.5,\n        50.5,  51.5,  52.5,  53.5,  54.5,  55.5,  56.5,  57.5,  58.5,  59.5,\n        60.5,  61.5,  62.5,  63.5,  64.5,  65.5,  66.5,  67.5,  68.5,  69.5,\n        70.5,  71.5,  72.5,  73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5])lon(lon)float640.5 1.5 2.5 ... 357.5 358.5 359.5axis :Xbounds :lon_bndslong_name :longitudestandard_name :longitudeunits :degrees_eastarray([  0.5,   1.5,   2.5, ..., 357.5, 358.5, 359.5], shape=(360,))Data variables: (4)time_bnds(time, d2)object...[24 values with dtype=object]lat_bnds(lat, d2)float64...long_name :latitude boundsunits :degrees_north[360 values with dtype=float64]lon_bnds(lon, d2)float64...long_name :longitude boundsunits :degrees_east[720 values with dtype=float64]tos(time, lat, lon)float32...cell_measures :area: areacellocell_methods :area: mean where sea time: meancomment :Model data on the 1x1 grid includes values in all cells for which ocean cells on the native grid cover more than 52.5 percent of the 1x1 grid cell. This 52.5 percent cutoff was chosen to produce ocean surface area on the 1x1 grid as close as possible to ocean surface area on the native grid, while not introducing fractional cell coverage.description :This may differ from \"surface temperature\" in regions of sea ice or floating ice shelves. For models using conservative temperature as the prognostic field, they should report the top ocean layer as surface potential temperature, which is the same as surface in situ temperature.frequency :monid :toslong_name :Sea Surface TemperaturemipTable :Omonout_name :tosprov :Omon ((isd.003))realm :oceanstandard_name :sea_surface_temperaturetime :timetime_label :time-meantime_title :Temporal meantitle :Sea Surface Temperaturetype :realunits :degCvariable_id :tos[777600 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(CFTimeIndex([2004-01-15 12:00:00, 2004-02-14 00:00:00, 2004-03-15 12:00:00,\n             2004-04-15 00:00:00, 2004-05-15 12:00:00, 2004-06-15 00:00:00,\n             2004-07-15 12:00:00, 2004-08-15 12:00:00, 2004-09-15 00:00:00,\n             2004-10-15 12:00:00, 2004-11-15 00:00:00, 2004-12-15 12:00:00],\n            dtype='object', length=12, calendar='noleap', freq=None))latPandasIndexPandasIndex(Index([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       ...\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5],\n      dtype='float64', name='lat', length=180))lonPandasIndexPandasIndex(Index([  0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n       ...\n       350.5, 351.5, 352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5],\n      dtype='float64', name='lon', length=360))Attributes: (45)Conventions :CF-1.7 CMIP-6.2activity_id :CMIPbranch_method :standardbranch_time_in_child :674885.0branch_time_in_parent :219000.0case_id :972cesm_casename :b.e21.BHIST.f09_g17.CMIP6-historical.011contact :cesm_cmip6@ucar.educreation_date :2019-04-02T04:44:58Zdata_specs_version :01.00.29experiment :Simulation of recent past (1850 to 2014). Impose changing conditions (consistent with observations). Should be initialised from a point early enough in the pre-industrial control run to ensure that the end of all the perturbed runs branching from the end of this historical run end before the end of the control. Only one ensemble member is requested but modelling groups are strongly encouraged to submit at least three ensemble members of their CMIP historical simulation. experiment_id :historicalexternal_variables :areacelloforcing_index :1frequency :monfurther_info_url :https://furtherinfo.es-doc.org/CMIP6.NCAR.CESM2.historical.none.r11i1p1f1grid :ocean data regridded from native gx1v7 displaced pole grid (384x320 latxlon) to 180x360 latxlon using conservative regriddinggrid_label :grinitialization_index :1institution :National Center for Atmospheric Research, Climate and Global Dynamics Laboratory, 1850 Table Mesa Drive, Boulder, CO 80305, USAinstitution_id :NCARlicense :CMIP6 model data produced by &lt;The National Center for Atmospheric Research&gt; is licensed under a Creative Commons Attribution-[]ShareAlike 4.0 International License (https://creativecommons.org/licenses/). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file)[]. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.mip_era :CMIP6model_doi_url :https://doi.org/10.5065/D67H1H0Vnominal_resolution :1x1 degreeparent_activity_id :CMIPparent_experiment_id :piControlparent_mip_era :CMIP6parent_source_id :CESM2parent_time_units :days since 0001-01-01 00:00:00parent_variant_label :r1i1p1f1physics_index :1product :model-outputrealization_index :11realm :oceansource :CESM2 (2017): atmosphere: CAM6 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); ocean: POP2 (320x384 longitude/latitude; 60 levels; top grid cell 0-10 m); sea_ice: CICE5.1 (same grid as ocean); land: CLM5 0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); aerosol: MAM4 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); atmoschem: MAM4 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); landIce: CISM2.1; ocnBgchem: MARBL (320x384 longitude/latitude; 60 levels; top grid cell 0-10 m)source_id :CESM2source_type :AOGCM BGCsub_experiment :nonesub_experiment_id :nonetable_id :Omontracking_id :hdl:21.14100/2975ffd3-1d7b-47e3-961a-33f212ea4eb2variable_id :tosvariant_info :CMIP6 20th century experiments (1850-2014) with CAM6, interactive land (CLM5), coupled ocean (POP2) with biogeochemistry (MARBL), interactive sea ice (CICE5.1), and non-evolving land ice (CISM2.1)variant_label :r11i1p1f1\n\n\nCheck out the attributes (you can click the drop down arrows). Notice the units are degrees C. If you wanted the temperature in Kelvins you can change them very much as you would change a column in Pandas.\n\nds.tos + 273.15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'tos' (time: 180, lat: 180, lon: 360)&gt; Size: 47MB\narray([[[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        ...,\n        [271.3552 , 271.3553 , 271.3554 , ..., 271.35495, 271.355  ,\n         271.3551 ],\n        [271.36005, 271.36014, 271.36023, ..., 271.35986, 271.35992,\n         271.36   ],\n        [271.36447, 271.36453, 271.3646 , ..., 271.3643 , 271.36435,\n         271.3644 ]],\n\n       [[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n...\n        [271.40677, 271.40674, 271.4067 , ..., 271.40695, 271.4069 ,\n         271.40683],\n        [271.41296, 271.41293, 271.41293, ..., 271.41306, 271.413  ,\n         271.41296],\n        [271.41772, 271.41772, 271.41772, ..., 271.41766, 271.4177 ,\n         271.4177 ]],\n\n       [[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        ...,\n        [271.39386, 271.39383, 271.3938 , ..., 271.39407, 271.394  ,\n         271.39392],\n        [271.39935, 271.39932, 271.39932, ..., 271.39948, 271.39944,\n         271.39938],\n        [271.40372, 271.40372, 271.40375, ..., 271.4037 , 271.4037 ,\n         271.40372]]], shape=(180, 180, 360), dtype=float32)\nCoordinates:\n  * time     (time) object 1kB 2000-01-15 12:00:00 ... 2014-12-15 12:00:00\n  * lat      (lat) float64 1kB -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n  * lon      (lon) float64 3kB 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5xarray.DataArray'tos'time: 180lat: 180lon: 360nan nan nan nan nan nan nan ... 271.4 271.4 271.4 271.4 271.4 271.4array([[[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        ...,\n        [271.3552 , 271.3553 , 271.3554 , ..., 271.35495, 271.355  ,\n         271.3551 ],\n        [271.36005, 271.36014, 271.36023, ..., 271.35986, 271.35992,\n         271.36   ],\n        [271.36447, 271.36453, 271.3646 , ..., 271.3643 , 271.36435,\n         271.3644 ]],\n\n       [[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n...\n        [271.40677, 271.40674, 271.4067 , ..., 271.40695, 271.4069 ,\n         271.40683],\n        [271.41296, 271.41293, 271.41293, ..., 271.41306, 271.413  ,\n         271.41296],\n        [271.41772, 271.41772, 271.41772, ..., 271.41766, 271.4177 ,\n         271.4177 ]],\n\n       [[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        ...,\n        [271.39386, 271.39383, 271.3938 , ..., 271.39407, 271.394  ,\n         271.39392],\n        [271.39935, 271.39932, 271.39932, ..., 271.39948, 271.39944,\n         271.39938],\n        [271.40372, 271.40372, 271.40375, ..., 271.4037 , 271.4037 ,\n         271.40372]]], shape=(180, 180, 360), dtype=float32)Coordinates: (3)time(time)object2000-01-15 12:00:00 ... 2014-12-...axis :Tbounds :time_bndsstandard_name :timetitle :timetype :doublearray([cftime.DatetimeNoLeap(2000, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 12, 15, 12, 0, 0, 0, has_year_zero=True)],\n      dtype=object)lat(lat)float64-89.5 -88.5 -87.5 ... 88.5 89.5axis :Ybounds :lat_bndslong_name :latitudestandard_name :latitudeunits :degrees_northarray([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       -79.5, -78.5, -77.5, -76.5, -75.5, -74.5, -73.5, -72.5, -71.5, -70.5,\n       -69.5, -68.5, -67.5, -66.5, -65.5, -64.5, -63.5, -62.5, -61.5, -60.5,\n       -59.5, -58.5, -57.5, -56.5, -55.5, -54.5, -53.5, -52.5, -51.5, -50.5,\n       -49.5, -48.5, -47.5, -46.5, -45.5, -44.5, -43.5, -42.5, -41.5, -40.5,\n       -39.5, -38.5, -37.5, -36.5, -35.5, -34.5, -33.5, -32.5, -31.5, -30.5,\n       -29.5, -28.5, -27.5, -26.5, -25.5, -24.5, -23.5, -22.5, -21.5, -20.5,\n       -19.5, -18.5, -17.5, -16.5, -15.5, -14.5, -13.5, -12.5, -11.5, -10.5,\n        -9.5,  -8.5,  -7.5,  -6.5,  -5.5,  -4.5,  -3.5,  -2.5,  -1.5,  -0.5,\n         0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n        10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,  19.5,\n        20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,  28.5,  29.5,\n        30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,  37.5,  38.5,  39.5,\n        40.5,  41.5,  42.5,  43.5,  44.5,  45.5,  46.5,  47.5,  48.5,  49.5,\n        50.5,  51.5,  52.5,  53.5,  54.5,  55.5,  56.5,  57.5,  58.5,  59.5,\n        60.5,  61.5,  62.5,  63.5,  64.5,  65.5,  66.5,  67.5,  68.5,  69.5,\n        70.5,  71.5,  72.5,  73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5])lon(lon)float640.5 1.5 2.5 ... 357.5 358.5 359.5axis :Xbounds :lon_bndslong_name :longitudestandard_name :longitudeunits :degrees_eastarray([  0.5,   1.5,   2.5, ..., 357.5, 358.5, 359.5], shape=(360,))Indexes: (3)timePandasIndexPandasIndex(CFTimeIndex([2000-01-15 12:00:00, 2000-02-14 00:00:00, 2000-03-15 12:00:00,\n             2000-04-15 00:00:00, 2000-05-15 12:00:00, 2000-06-15 00:00:00,\n             2000-07-15 12:00:00, 2000-08-15 12:00:00, 2000-09-15 00:00:00,\n             2000-10-15 12:00:00,\n             ...\n             2014-03-15 12:00:00, 2014-04-15 00:00:00, 2014-05-15 12:00:00,\n             2014-06-15 00:00:00, 2014-07-15 12:00:00, 2014-08-15 12:00:00,\n             2014-09-15 00:00:00, 2014-10-15 12:00:00, 2014-11-15 00:00:00,\n             2014-12-15 12:00:00],\n            dtype='object', length=180, calendar='noleap', freq=None))latPandasIndexPandasIndex(Index([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       ...\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5],\n      dtype='float64', name='lat', length=180))lonPandasIndexPandasIndex(Index([  0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n       ...\n       350.5, 351.5, 352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5],\n      dtype='float64', name='lon', length=360))Attributes: (0)\n\n\nBoom Kelvins!\n\n\n\n\n\n\nNote\n\n\n\nDo you notice all of those NaNs? This is sea surface temperature, so where there is land, there is no data."
  },
  {
    "objectID": "Xarray.html#working-with-spatio-temporal-data",
    "href": "Xarray.html#working-with-spatio-temporal-data",
    "title": "Xarray",
    "section": "",
    "text": "In this tutorial we will be looking at sea surface temperatures using Community Earth System Model 2 (CESM2) data. This tutorial borrows heavily from this tutorial by Computational Tools in Climate Science. That tutorial has much more information about climatology, the focus here is using Xarray for data cubes.\nThis is gridded climate data given in lat, lon coordinates. In the rioXarray tutorials we will learn to deal with projections etc…\nFirst import libraries and download dataset.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\nfrom pythia_datasets import DATASETS\nimport matplotlib.pyplot as plt\n\n\nfilepath = DATASETS.fetch('CESM2_sst_data.nc')\n\nOpen the dataset and inspect. It is an Xarray Dataset. It has coordinates lat, lon, and time. It has corresponding indices It has spatial and time coordinates, hence we call it a spatio-temporal dataset.\n\nds = xr.open_dataset(filepath)\nds\n\n/home/michael/miniconda3/envs/geo3/lib/python3.12/site-packages/xarray/conventions.py:204: SerializationWarning: variable 'tos' has multiple fill values {np.float32(1e+20), np.float64(1e+20)} defined, decoding all values to NaN.\n  var = coder.decode(var, name=name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 47MB\nDimensions:    (time: 180, d2: 2, lat: 180, lon: 360)\nCoordinates:\n  * time       (time) object 1kB 2000-01-15 12:00:00 ... 2014-12-15 12:00:00\n  * lat        (lat) float64 1kB -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n  * lon        (lon) float64 3kB 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5\nDimensions without coordinates: d2\nData variables:\n    time_bnds  (time, d2) object 3kB ...\n    lat_bnds   (lat, d2) float64 3kB ...\n    lon_bnds   (lon, d2) float64 6kB ...\n    tos        (time, lat, lon) float32 47MB ...\nAttributes: (12/45)\n    Conventions:            CF-1.7 CMIP-6.2\n    activity_id:            CMIP\n    branch_method:          standard\n    branch_time_in_child:   674885.0\n    branch_time_in_parent:  219000.0\n    case_id:                972\n    ...                     ...\n    sub_experiment_id:      none\n    table_id:               Omon\n    tracking_id:            hdl:21.14100/2975ffd3-1d7b-47e3-961a-33f212ea4eb2\n    variable_id:            tos\n    variant_info:           CMIP6 20th century experiments (1850-2014) with C...\n    variant_label:          r11i1p1f1xarray.DatasetDimensions:time: 180d2: 2lat: 180lon: 360Coordinates: (3)time(time)object2000-01-15 12:00:00 ... 2014-12-...axis :Tbounds :time_bndsstandard_name :timetitle :timetype :doublearray([cftime.DatetimeNoLeap(2000, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 12, 15, 12, 0, 0, 0, has_year_zero=True)],\n      dtype=object)lat(lat)float64-89.5 -88.5 -87.5 ... 88.5 89.5axis :Ybounds :lat_bndslong_name :latitudestandard_name :latitudeunits :degrees_northarray([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       -79.5, -78.5, -77.5, -76.5, -75.5, -74.5, -73.5, -72.5, -71.5, -70.5,\n       -69.5, -68.5, -67.5, -66.5, -65.5, -64.5, -63.5, -62.5, -61.5, -60.5,\n       -59.5, -58.5, -57.5, -56.5, -55.5, -54.5, -53.5, -52.5, -51.5, -50.5,\n       -49.5, -48.5, -47.5, -46.5, -45.5, -44.5, -43.5, -42.5, -41.5, -40.5,\n       -39.5, -38.5, -37.5, -36.5, -35.5, -34.5, -33.5, -32.5, -31.5, -30.5,\n       -29.5, -28.5, -27.5, -26.5, -25.5, -24.5, -23.5, -22.5, -21.5, -20.5,\n       -19.5, -18.5, -17.5, -16.5, -15.5, -14.5, -13.5, -12.5, -11.5, -10.5,\n        -9.5,  -8.5,  -7.5,  -6.5,  -5.5,  -4.5,  -3.5,  -2.5,  -1.5,  -0.5,\n         0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n        10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,  19.5,\n        20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,  28.5,  29.5,\n        30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,  37.5,  38.5,  39.5,\n        40.5,  41.5,  42.5,  43.5,  44.5,  45.5,  46.5,  47.5,  48.5,  49.5,\n        50.5,  51.5,  52.5,  53.5,  54.5,  55.5,  56.5,  57.5,  58.5,  59.5,\n        60.5,  61.5,  62.5,  63.5,  64.5,  65.5,  66.5,  67.5,  68.5,  69.5,\n        70.5,  71.5,  72.5,  73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5])lon(lon)float640.5 1.5 2.5 ... 357.5 358.5 359.5axis :Xbounds :lon_bndslong_name :longitudestandard_name :longitudeunits :degrees_eastarray([  0.5,   1.5,   2.5, ..., 357.5, 358.5, 359.5], shape=(360,))Data variables: (4)time_bnds(time, d2)object...[360 values with dtype=object]lat_bnds(lat, d2)float64...long_name :latitude boundsunits :degrees_north[360 values with dtype=float64]lon_bnds(lon, d2)float64...long_name :longitude boundsunits :degrees_east[720 values with dtype=float64]tos(time, lat, lon)float32...cell_measures :area: areacellocell_methods :area: mean where sea time: meancomment :Model data on the 1x1 grid includes values in all cells for which ocean cells on the native grid cover more than 52.5 percent of the 1x1 grid cell. This 52.5 percent cutoff was chosen to produce ocean surface area on the 1x1 grid as close as possible to ocean surface area on the native grid, while not introducing fractional cell coverage.description :This may differ from \"surface temperature\" in regions of sea ice or floating ice shelves. For models using conservative temperature as the prognostic field, they should report the top ocean layer as surface potential temperature, which is the same as surface in situ temperature.frequency :monid :toslong_name :Sea Surface TemperaturemipTable :Omonout_name :tosprov :Omon ((isd.003))realm :oceanstandard_name :sea_surface_temperaturetime :timetime_label :time-meantime_title :Temporal meantitle :Sea Surface Temperaturetype :realunits :degCvariable_id :tos[11664000 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(CFTimeIndex([2000-01-15 12:00:00, 2000-02-14 00:00:00, 2000-03-15 12:00:00,\n             2000-04-15 00:00:00, 2000-05-15 12:00:00, 2000-06-15 00:00:00,\n             2000-07-15 12:00:00, 2000-08-15 12:00:00, 2000-09-15 00:00:00,\n             2000-10-15 12:00:00,\n             ...\n             2014-03-15 12:00:00, 2014-04-15 00:00:00, 2014-05-15 12:00:00,\n             2014-06-15 00:00:00, 2014-07-15 12:00:00, 2014-08-15 12:00:00,\n             2014-09-15 00:00:00, 2014-10-15 12:00:00, 2014-11-15 00:00:00,\n             2014-12-15 12:00:00],\n            dtype='object', length=180, calendar='noleap', freq=None))latPandasIndexPandasIndex(Index([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       ...\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5],\n      dtype='float64', name='lat', length=180))lonPandasIndexPandasIndex(Index([  0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n       ...\n       350.5, 351.5, 352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5],\n      dtype='float64', name='lon', length=360))Attributes: (45)Conventions :CF-1.7 CMIP-6.2activity_id :CMIPbranch_method :standardbranch_time_in_child :674885.0branch_time_in_parent :219000.0case_id :972cesm_casename :b.e21.BHIST.f09_g17.CMIP6-historical.011contact :cesm_cmip6@ucar.educreation_date :2019-04-02T04:44:58Zdata_specs_version :01.00.29experiment :Simulation of recent past (1850 to 2014). Impose changing conditions (consistent with observations). Should be initialised from a point early enough in the pre-industrial control run to ensure that the end of all the perturbed runs branching from the end of this historical run end before the end of the control. Only one ensemble member is requested but modelling groups are strongly encouraged to submit at least three ensemble members of their CMIP historical simulation. experiment_id :historicalexternal_variables :areacelloforcing_index :1frequency :monfurther_info_url :https://furtherinfo.es-doc.org/CMIP6.NCAR.CESM2.historical.none.r11i1p1f1grid :ocean data regridded from native gx1v7 displaced pole grid (384x320 latxlon) to 180x360 latxlon using conservative regriddinggrid_label :grinitialization_index :1institution :National Center for Atmospheric Research, Climate and Global Dynamics Laboratory, 1850 Table Mesa Drive, Boulder, CO 80305, USAinstitution_id :NCARlicense :CMIP6 model data produced by &lt;The National Center for Atmospheric Research&gt; is licensed under a Creative Commons Attribution-[]ShareAlike 4.0 International License (https://creativecommons.org/licenses/). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file)[]. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.mip_era :CMIP6model_doi_url :https://doi.org/10.5065/D67H1H0Vnominal_resolution :1x1 degreeparent_activity_id :CMIPparent_experiment_id :piControlparent_mip_era :CMIP6parent_source_id :CESM2parent_time_units :days since 0001-01-01 00:00:00parent_variant_label :r1i1p1f1physics_index :1product :model-outputrealization_index :11realm :oceansource :CESM2 (2017): atmosphere: CAM6 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); ocean: POP2 (320x384 longitude/latitude; 60 levels; top grid cell 0-10 m); sea_ice: CICE5.1 (same grid as ocean); land: CLM5 0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); aerosol: MAM4 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); atmoschem: MAM4 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); landIce: CISM2.1; ocnBgchem: MARBL (320x384 longitude/latitude; 60 levels; top grid cell 0-10 m)source_id :CESM2source_type :AOGCM BGCsub_experiment :nonesub_experiment_id :nonetable_id :Omontracking_id :hdl:21.14100/2975ffd3-1d7b-47e3-961a-33f212ea4eb2variable_id :tosvariant_info :CMIP6 20th century experiments (1850-2014) with CAM6, interactive land (CLM5), coupled ocean (POP2) with biogeochemistry (MARBL), interactive sea ice (CICE5.1), and non-evolving land ice (CISM2.1)variant_label :r11i1p1f1\n\n\nYou can subset the data along an axis with slicing (here we explicitly create a slice object)\n\nds.sel(\n    time=slice('2004-01-01', '2004-12-31')\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3MB\nDimensions:    (time: 12, d2: 2, lat: 180, lon: 360)\nCoordinates:\n  * time       (time) object 96B 2004-01-15 12:00:00 ... 2004-12-15 12:00:00\n  * lat        (lat) float64 1kB -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n  * lon        (lon) float64 3kB 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5\nDimensions without coordinates: d2\nData variables:\n    time_bnds  (time, d2) object 192B ...\n    lat_bnds   (lat, d2) float64 3kB ...\n    lon_bnds   (lon, d2) float64 6kB ...\n    tos        (time, lat, lon) float32 3MB ...\nAttributes: (12/45)\n    Conventions:            CF-1.7 CMIP-6.2\n    activity_id:            CMIP\n    branch_method:          standard\n    branch_time_in_child:   674885.0\n    branch_time_in_parent:  219000.0\n    case_id:                972\n    ...                     ...\n    sub_experiment_id:      none\n    table_id:               Omon\n    tracking_id:            hdl:21.14100/2975ffd3-1d7b-47e3-961a-33f212ea4eb2\n    variable_id:            tos\n    variant_info:           CMIP6 20th century experiments (1850-2014) with C...\n    variant_label:          r11i1p1f1xarray.DatasetDimensions:time: 12d2: 2lat: 180lon: 360Coordinates: (3)time(time)object2004-01-15 12:00:00 ... 2004-12-...axis :Tbounds :time_bndsstandard_name :timetitle :timetype :doublearray([cftime.DatetimeNoLeap(2004, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 12, 15, 12, 0, 0, 0, has_year_zero=True)],\n      dtype=object)lat(lat)float64-89.5 -88.5 -87.5 ... 88.5 89.5axis :Ybounds :lat_bndslong_name :latitudestandard_name :latitudeunits :degrees_northarray([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       -79.5, -78.5, -77.5, -76.5, -75.5, -74.5, -73.5, -72.5, -71.5, -70.5,\n       -69.5, -68.5, -67.5, -66.5, -65.5, -64.5, -63.5, -62.5, -61.5, -60.5,\n       -59.5, -58.5, -57.5, -56.5, -55.5, -54.5, -53.5, -52.5, -51.5, -50.5,\n       -49.5, -48.5, -47.5, -46.5, -45.5, -44.5, -43.5, -42.5, -41.5, -40.5,\n       -39.5, -38.5, -37.5, -36.5, -35.5, -34.5, -33.5, -32.5, -31.5, -30.5,\n       -29.5, -28.5, -27.5, -26.5, -25.5, -24.5, -23.5, -22.5, -21.5, -20.5,\n       -19.5, -18.5, -17.5, -16.5, -15.5, -14.5, -13.5, -12.5, -11.5, -10.5,\n        -9.5,  -8.5,  -7.5,  -6.5,  -5.5,  -4.5,  -3.5,  -2.5,  -1.5,  -0.5,\n         0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n        10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,  19.5,\n        20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,  28.5,  29.5,\n        30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,  37.5,  38.5,  39.5,\n        40.5,  41.5,  42.5,  43.5,  44.5,  45.5,  46.5,  47.5,  48.5,  49.5,\n        50.5,  51.5,  52.5,  53.5,  54.5,  55.5,  56.5,  57.5,  58.5,  59.5,\n        60.5,  61.5,  62.5,  63.5,  64.5,  65.5,  66.5,  67.5,  68.5,  69.5,\n        70.5,  71.5,  72.5,  73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5])lon(lon)float640.5 1.5 2.5 ... 357.5 358.5 359.5axis :Xbounds :lon_bndslong_name :longitudestandard_name :longitudeunits :degrees_eastarray([  0.5,   1.5,   2.5, ..., 357.5, 358.5, 359.5], shape=(360,))Data variables: (4)time_bnds(time, d2)object...[24 values with dtype=object]lat_bnds(lat, d2)float64...long_name :latitude boundsunits :degrees_north[360 values with dtype=float64]lon_bnds(lon, d2)float64...long_name :longitude boundsunits :degrees_east[720 values with dtype=float64]tos(time, lat, lon)float32...cell_measures :area: areacellocell_methods :area: mean where sea time: meancomment :Model data on the 1x1 grid includes values in all cells for which ocean cells on the native grid cover more than 52.5 percent of the 1x1 grid cell. This 52.5 percent cutoff was chosen to produce ocean surface area on the 1x1 grid as close as possible to ocean surface area on the native grid, while not introducing fractional cell coverage.description :This may differ from \"surface temperature\" in regions of sea ice or floating ice shelves. For models using conservative temperature as the prognostic field, they should report the top ocean layer as surface potential temperature, which is the same as surface in situ temperature.frequency :monid :toslong_name :Sea Surface TemperaturemipTable :Omonout_name :tosprov :Omon ((isd.003))realm :oceanstandard_name :sea_surface_temperaturetime :timetime_label :time-meantime_title :Temporal meantitle :Sea Surface Temperaturetype :realunits :degCvariable_id :tos[777600 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(CFTimeIndex([2004-01-15 12:00:00, 2004-02-14 00:00:00, 2004-03-15 12:00:00,\n             2004-04-15 00:00:00, 2004-05-15 12:00:00, 2004-06-15 00:00:00,\n             2004-07-15 12:00:00, 2004-08-15 12:00:00, 2004-09-15 00:00:00,\n             2004-10-15 12:00:00, 2004-11-15 00:00:00, 2004-12-15 12:00:00],\n            dtype='object', length=12, calendar='noleap', freq=None))latPandasIndexPandasIndex(Index([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       ...\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5],\n      dtype='float64', name='lat', length=180))lonPandasIndexPandasIndex(Index([  0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n       ...\n       350.5, 351.5, 352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5],\n      dtype='float64', name='lon', length=360))Attributes: (45)Conventions :CF-1.7 CMIP-6.2activity_id :CMIPbranch_method :standardbranch_time_in_child :674885.0branch_time_in_parent :219000.0case_id :972cesm_casename :b.e21.BHIST.f09_g17.CMIP6-historical.011contact :cesm_cmip6@ucar.educreation_date :2019-04-02T04:44:58Zdata_specs_version :01.00.29experiment :Simulation of recent past (1850 to 2014). Impose changing conditions (consistent with observations). Should be initialised from a point early enough in the pre-industrial control run to ensure that the end of all the perturbed runs branching from the end of this historical run end before the end of the control. Only one ensemble member is requested but modelling groups are strongly encouraged to submit at least three ensemble members of their CMIP historical simulation. experiment_id :historicalexternal_variables :areacelloforcing_index :1frequency :monfurther_info_url :https://furtherinfo.es-doc.org/CMIP6.NCAR.CESM2.historical.none.r11i1p1f1grid :ocean data regridded from native gx1v7 displaced pole grid (384x320 latxlon) to 180x360 latxlon using conservative regriddinggrid_label :grinitialization_index :1institution :National Center for Atmospheric Research, Climate and Global Dynamics Laboratory, 1850 Table Mesa Drive, Boulder, CO 80305, USAinstitution_id :NCARlicense :CMIP6 model data produced by &lt;The National Center for Atmospheric Research&gt; is licensed under a Creative Commons Attribution-[]ShareAlike 4.0 International License (https://creativecommons.org/licenses/). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file)[]. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.mip_era :CMIP6model_doi_url :https://doi.org/10.5065/D67H1H0Vnominal_resolution :1x1 degreeparent_activity_id :CMIPparent_experiment_id :piControlparent_mip_era :CMIP6parent_source_id :CESM2parent_time_units :days since 0001-01-01 00:00:00parent_variant_label :r1i1p1f1physics_index :1product :model-outputrealization_index :11realm :oceansource :CESM2 (2017): atmosphere: CAM6 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); ocean: POP2 (320x384 longitude/latitude; 60 levels; top grid cell 0-10 m); sea_ice: CICE5.1 (same grid as ocean); land: CLM5 0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); aerosol: MAM4 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); atmoschem: MAM4 (0.9x1.25 finite volume grid; 288 x 192 longitude/latitude; 32 levels; top level 2.25 mb); landIce: CISM2.1; ocnBgchem: MARBL (320x384 longitude/latitude; 60 levels; top grid cell 0-10 m)source_id :CESM2source_type :AOGCM BGCsub_experiment :nonesub_experiment_id :nonetable_id :Omontracking_id :hdl:21.14100/2975ffd3-1d7b-47e3-961a-33f212ea4eb2variable_id :tosvariant_info :CMIP6 20th century experiments (1850-2014) with CAM6, interactive land (CLM5), coupled ocean (POP2) with biogeochemistry (MARBL), interactive sea ice (CICE5.1), and non-evolving land ice (CISM2.1)variant_label :r11i1p1f1\n\n\nCheck out the attributes (you can click the drop down arrows). Notice the units are degrees C. If you wanted the temperature in Kelvins you can change them very much as you would change a column in Pandas.\n\nds.tos + 273.15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'tos' (time: 180, lat: 180, lon: 360)&gt; Size: 47MB\narray([[[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        ...,\n        [271.3552 , 271.3553 , 271.3554 , ..., 271.35495, 271.355  ,\n         271.3551 ],\n        [271.36005, 271.36014, 271.36023, ..., 271.35986, 271.35992,\n         271.36   ],\n        [271.36447, 271.36453, 271.3646 , ..., 271.3643 , 271.36435,\n         271.3644 ]],\n\n       [[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n...\n        [271.40677, 271.40674, 271.4067 , ..., 271.40695, 271.4069 ,\n         271.40683],\n        [271.41296, 271.41293, 271.41293, ..., 271.41306, 271.413  ,\n         271.41296],\n        [271.41772, 271.41772, 271.41772, ..., 271.41766, 271.4177 ,\n         271.4177 ]],\n\n       [[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        ...,\n        [271.39386, 271.39383, 271.3938 , ..., 271.39407, 271.394  ,\n         271.39392],\n        [271.39935, 271.39932, 271.39932, ..., 271.39948, 271.39944,\n         271.39938],\n        [271.40372, 271.40372, 271.40375, ..., 271.4037 , 271.4037 ,\n         271.40372]]], shape=(180, 180, 360), dtype=float32)\nCoordinates:\n  * time     (time) object 1kB 2000-01-15 12:00:00 ... 2014-12-15 12:00:00\n  * lat      (lat) float64 1kB -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n  * lon      (lon) float64 3kB 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5xarray.DataArray'tos'time: 180lat: 180lon: 360nan nan nan nan nan nan nan ... 271.4 271.4 271.4 271.4 271.4 271.4array([[[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        ...,\n        [271.3552 , 271.3553 , 271.3554 , ..., 271.35495, 271.355  ,\n         271.3551 ],\n        [271.36005, 271.36014, 271.36023, ..., 271.35986, 271.35992,\n         271.36   ],\n        [271.36447, 271.36453, 271.3646 , ..., 271.3643 , 271.36435,\n         271.3644 ]],\n\n       [[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n...\n        [271.40677, 271.40674, 271.4067 , ..., 271.40695, 271.4069 ,\n         271.40683],\n        [271.41296, 271.41293, 271.41293, ..., 271.41306, 271.413  ,\n         271.41296],\n        [271.41772, 271.41772, 271.41772, ..., 271.41766, 271.4177 ,\n         271.4177 ]],\n\n       [[      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        [      nan,       nan,       nan, ...,       nan,       nan,\n               nan],\n        ...,\n        [271.39386, 271.39383, 271.3938 , ..., 271.39407, 271.394  ,\n         271.39392],\n        [271.39935, 271.39932, 271.39932, ..., 271.39948, 271.39944,\n         271.39938],\n        [271.40372, 271.40372, 271.40375, ..., 271.4037 , 271.4037 ,\n         271.40372]]], shape=(180, 180, 360), dtype=float32)Coordinates: (3)time(time)object2000-01-15 12:00:00 ... 2014-12-...axis :Tbounds :time_bndsstandard_name :timetitle :timetype :doublearray([cftime.DatetimeNoLeap(2000, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2000, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2001, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2002, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2003, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2004, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2005, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2006, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2007, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2008, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2009, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2010, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2011, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2012, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2013, 12, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 1, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 2, 14, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 3, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 4, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 5, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 6, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 7, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 8, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 9, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 10, 15, 12, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 11, 15, 0, 0, 0, 0, has_year_zero=True),\n       cftime.DatetimeNoLeap(2014, 12, 15, 12, 0, 0, 0, has_year_zero=True)],\n      dtype=object)lat(lat)float64-89.5 -88.5 -87.5 ... 88.5 89.5axis :Ybounds :lat_bndslong_name :latitudestandard_name :latitudeunits :degrees_northarray([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       -79.5, -78.5, -77.5, -76.5, -75.5, -74.5, -73.5, -72.5, -71.5, -70.5,\n       -69.5, -68.5, -67.5, -66.5, -65.5, -64.5, -63.5, -62.5, -61.5, -60.5,\n       -59.5, -58.5, -57.5, -56.5, -55.5, -54.5, -53.5, -52.5, -51.5, -50.5,\n       -49.5, -48.5, -47.5, -46.5, -45.5, -44.5, -43.5, -42.5, -41.5, -40.5,\n       -39.5, -38.5, -37.5, -36.5, -35.5, -34.5, -33.5, -32.5, -31.5, -30.5,\n       -29.5, -28.5, -27.5, -26.5, -25.5, -24.5, -23.5, -22.5, -21.5, -20.5,\n       -19.5, -18.5, -17.5, -16.5, -15.5, -14.5, -13.5, -12.5, -11.5, -10.5,\n        -9.5,  -8.5,  -7.5,  -6.5,  -5.5,  -4.5,  -3.5,  -2.5,  -1.5,  -0.5,\n         0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n        10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,  19.5,\n        20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,  28.5,  29.5,\n        30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,  37.5,  38.5,  39.5,\n        40.5,  41.5,  42.5,  43.5,  44.5,  45.5,  46.5,  47.5,  48.5,  49.5,\n        50.5,  51.5,  52.5,  53.5,  54.5,  55.5,  56.5,  57.5,  58.5,  59.5,\n        60.5,  61.5,  62.5,  63.5,  64.5,  65.5,  66.5,  67.5,  68.5,  69.5,\n        70.5,  71.5,  72.5,  73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5])lon(lon)float640.5 1.5 2.5 ... 357.5 358.5 359.5axis :Xbounds :lon_bndslong_name :longitudestandard_name :longitudeunits :degrees_eastarray([  0.5,   1.5,   2.5, ..., 357.5, 358.5, 359.5], shape=(360,))Indexes: (3)timePandasIndexPandasIndex(CFTimeIndex([2000-01-15 12:00:00, 2000-02-14 00:00:00, 2000-03-15 12:00:00,\n             2000-04-15 00:00:00, 2000-05-15 12:00:00, 2000-06-15 00:00:00,\n             2000-07-15 12:00:00, 2000-08-15 12:00:00, 2000-09-15 00:00:00,\n             2000-10-15 12:00:00,\n             ...\n             2014-03-15 12:00:00, 2014-04-15 00:00:00, 2014-05-15 12:00:00,\n             2014-06-15 00:00:00, 2014-07-15 12:00:00, 2014-08-15 12:00:00,\n             2014-09-15 00:00:00, 2014-10-15 12:00:00, 2014-11-15 00:00:00,\n             2014-12-15 12:00:00],\n            dtype='object', length=180, calendar='noleap', freq=None))latPandasIndexPandasIndex(Index([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       ...\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5],\n      dtype='float64', name='lat', length=180))lonPandasIndexPandasIndex(Index([  0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n       ...\n       350.5, 351.5, 352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5],\n      dtype='float64', name='lon', length=360))Attributes: (0)\n\n\nBoom Kelvins!\n\n\n\n\n\n\nNote\n\n\n\nDo you notice all of those NaNs? This is sea surface temperature, so where there is land, there is no data."
  },
  {
    "objectID": "Xarray.html#aggregations",
    "href": "Xarray.html#aggregations",
    "title": "Xarray",
    "section": "Aggregations",
    "text": "Aggregations\nA common thing to do in performing various types of analysis is to apply aggregations such as .sum(), .mean(), .median(), .min(), or .max(). These methods can be used to reduce data to provide insights into the nature of a large dataset. For example, one might want to calculate the minimum temperature for each cell (temporal minimum).\n\nglobal_min = ds.tos.min(dim='time')\nglobal_min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'tos' (lat: 180, lon: 360)&gt; Size: 259kB\narray([[       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       ...,\n       [-1.8083605, -1.8083031, -1.8082187, ..., -1.8083988, -1.8083944,\n        -1.8083915],\n       [-1.8025414, -1.8024837, -1.8024155, ..., -1.8026428, -1.8026177,\n        -1.8025846],\n       [-1.7984415, -1.7983989, -1.7983514, ..., -1.7985678, -1.7985296,\n        -1.7984871]], shape=(180, 360), dtype=float32)\nCoordinates:\n  * lat      (lat) float64 1kB -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n  * lon      (lon) float64 3kB 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5xarray.DataArray'tos'lat: 180lon: 360nan nan nan nan nan nan ... -1.799 -1.799 -1.799 -1.799 -1.799 -1.798array([[       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       [       nan,        nan,        nan, ...,        nan,        nan,\n               nan],\n       ...,\n       [-1.8083605, -1.8083031, -1.8082187, ..., -1.8083988, -1.8083944,\n        -1.8083915],\n       [-1.8025414, -1.8024837, -1.8024155, ..., -1.8026428, -1.8026177,\n        -1.8025846],\n       [-1.7984415, -1.7983989, -1.7983514, ..., -1.7985678, -1.7985296,\n        -1.7984871]], shape=(180, 360), dtype=float32)Coordinates: (2)lat(lat)float64-89.5 -88.5 -87.5 ... 88.5 89.5axis :Ybounds :lat_bndslong_name :latitudestandard_name :latitudeunits :degrees_northarray([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       -79.5, -78.5, -77.5, -76.5, -75.5, -74.5, -73.5, -72.5, -71.5, -70.5,\n       -69.5, -68.5, -67.5, -66.5, -65.5, -64.5, -63.5, -62.5, -61.5, -60.5,\n       -59.5, -58.5, -57.5, -56.5, -55.5, -54.5, -53.5, -52.5, -51.5, -50.5,\n       -49.5, -48.5, -47.5, -46.5, -45.5, -44.5, -43.5, -42.5, -41.5, -40.5,\n       -39.5, -38.5, -37.5, -36.5, -35.5, -34.5, -33.5, -32.5, -31.5, -30.5,\n       -29.5, -28.5, -27.5, -26.5, -25.5, -24.5, -23.5, -22.5, -21.5, -20.5,\n       -19.5, -18.5, -17.5, -16.5, -15.5, -14.5, -13.5, -12.5, -11.5, -10.5,\n        -9.5,  -8.5,  -7.5,  -6.5,  -5.5,  -4.5,  -3.5,  -2.5,  -1.5,  -0.5,\n         0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n        10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,  19.5,\n        20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,  28.5,  29.5,\n        30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,  37.5,  38.5,  39.5,\n        40.5,  41.5,  42.5,  43.5,  44.5,  45.5,  46.5,  47.5,  48.5,  49.5,\n        50.5,  51.5,  52.5,  53.5,  54.5,  55.5,  56.5,  57.5,  58.5,  59.5,\n        60.5,  61.5,  62.5,  63.5,  64.5,  65.5,  66.5,  67.5,  68.5,  69.5,\n        70.5,  71.5,  72.5,  73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5])lon(lon)float640.5 1.5 2.5 ... 357.5 358.5 359.5axis :Xbounds :lon_bndslong_name :longitudestandard_name :longitudeunits :degrees_eastarray([  0.5,   1.5,   2.5, ..., 357.5, 358.5, 359.5], shape=(360,))Indexes: (2)latPandasIndexPandasIndex(Index([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       ...\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5],\n      dtype='float64', name='lat', length=180))lonPandasIndexPandasIndex(Index([  0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n       ...\n       350.5, 351.5, 352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5],\n      dtype='float64', name='lon', length=360))Attributes: (0)\n\n\nPay attention to the dimensions of the above output. We have collapsed the time dimension using the .min() method, so we are left with a 2D grid of lat and lon.\n\nfig, ax  = plt.subplots();\ntitle = f'Minimum annual SST {ds.time.min().item().year} - {ds.time.max().item().year}'\nglobal_min.plot(cmap='inferno', ax=ax, cbar_kwargs={'label': 'degrees C'});\nax.set_title(title );\n\n\n\n\n\n\n\n\nWe could also aggregate spatially, for instance we could find the mean the sea surface temperature across the entire grid at eac time step, leaving us with a 1D timeseries of mean temperatures.\n\nt_mean = ds.tos.mean(dim=[\"lat\", \"lon\"])\nt_mean\n\nfig, ax  = plt.subplots();\nt_mean.plot()\n\ntitle = f'Global Mean SST {ds.time.min().item().year} - {ds.time.max().item().year}'\nax.set_title(title);\nax.set_ylabel('degrees C');\nax.set_xlabel('Year');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nNow that you know how to slice and aggregate, find and plot a map of maximum SST for the year 2005."
  },
  {
    "objectID": "Xarray.html#groupby-split-apply-combine",
    "href": "Xarray.html#groupby-split-apply-combine",
    "title": "Xarray",
    "section": "GroupBy: Split, Apply, Combine",
    "text": "GroupBy: Split, Apply, Combine\nOften it is useful to aggregate conditionally on some coordinate labels or groups.\n\nHere we will use a split-apply-combine workflow to remove seasonal cycles from the data.\nHere is the splitting alone using .groupby\n\nds.tos.groupby(ds.time.dt.month)\n\n&lt;DataArrayGroupBy, grouped over 1 grouper(s), 12 groups in total:\n    'month': 12/12 groups present with labels 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12&gt;\n\n\n\ngrouped_mean = ds.tos.groupby(ds.time.dt.month).mean()\ngrouped_mean\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'tos' (month: 12, lat: 180, lon: 360)&gt; Size: 3MB\narray([[[       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        ...,\n        [-1.780786 , -1.780688 , -1.7805718, ..., -1.7809757,\n         -1.7809197, -1.7808627],\n        [-1.7745041, -1.7744204, -1.7743237, ..., -1.77467  ,\n         -1.774626 , -1.7745715],\n        [-1.7691481, -1.7690798, -1.7690051, ..., -1.7693441,\n         -1.7692844, -1.7692182]],\n\n       [[       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n...\n        [-1.7605033, -1.760397 , -1.7602725, ..., -1.760718 ,\n         -1.7606541, -1.7605885],\n        [-1.7544289, -1.7543424, -1.7542422, ..., -1.754608 ,\n         -1.754559 , -1.7545002],\n        [-1.7492163, -1.749148 , -1.7490736, ..., -1.7494118,\n         -1.7493519, -1.7492864]],\n\n       [[       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        ...,\n        [-1.7711828, -1.7710832, -1.7709653, ..., -1.7713748,\n         -1.7713183, -1.7712607],\n        [-1.7648666, -1.7647841, -1.7646879, ..., -1.7650299,\n         -1.7649865, -1.7649331],\n        [-1.759478 , -1.7594113, -1.7593384, ..., -1.7596704,\n         -1.7596117, -1.759547 ]]], shape=(12, 180, 360), dtype=float32)\nCoordinates:\n  * lat      (lat) float64 1kB -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n  * lon      (lon) float64 3kB 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5\n  * month    (month) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\nAttributes: (12/19)\n    cell_measures:  area: areacello\n    cell_methods:   area: mean where sea time: mean\n    comment:        Model data on the 1x1 grid includes values in all cells f...\n    description:    This may differ from \"surface temperature\" in regions of ...\n    frequency:      mon\n    id:             tos\n    ...             ...\n    time_label:     time-mean\n    time_title:     Temporal mean\n    title:          Sea Surface Temperature\n    type:           real\n    units:          degC\n    variable_id:    tosxarray.DataArray'tos'month: 12lat: 180lon: 360nan nan nan nan nan nan nan ... -1.76 -1.76 -1.76 -1.76 -1.76 -1.76array([[[       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        ...,\n        [-1.780786 , -1.780688 , -1.7805718, ..., -1.7809757,\n         -1.7809197, -1.7808627],\n        [-1.7745041, -1.7744204, -1.7743237, ..., -1.77467  ,\n         -1.774626 , -1.7745715],\n        [-1.7691481, -1.7690798, -1.7690051, ..., -1.7693441,\n         -1.7692844, -1.7692182]],\n\n       [[       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n...\n        [-1.7605033, -1.760397 , -1.7602725, ..., -1.760718 ,\n         -1.7606541, -1.7605885],\n        [-1.7544289, -1.7543424, -1.7542422, ..., -1.754608 ,\n         -1.754559 , -1.7545002],\n        [-1.7492163, -1.749148 , -1.7490736, ..., -1.7494118,\n         -1.7493519, -1.7492864]],\n\n       [[       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        ...,\n        [-1.7711828, -1.7710832, -1.7709653, ..., -1.7713748,\n         -1.7713183, -1.7712607],\n        [-1.7648666, -1.7647841, -1.7646879, ..., -1.7650299,\n         -1.7649865, -1.7649331],\n        [-1.759478 , -1.7594113, -1.7593384, ..., -1.7596704,\n         -1.7596117, -1.759547 ]]], shape=(12, 180, 360), dtype=float32)Coordinates: (3)lat(lat)float64-89.5 -88.5 -87.5 ... 88.5 89.5axis :Ybounds :lat_bndslong_name :latitudestandard_name :latitudeunits :degrees_northarray([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       -79.5, -78.5, -77.5, -76.5, -75.5, -74.5, -73.5, -72.5, -71.5, -70.5,\n       -69.5, -68.5, -67.5, -66.5, -65.5, -64.5, -63.5, -62.5, -61.5, -60.5,\n       -59.5, -58.5, -57.5, -56.5, -55.5, -54.5, -53.5, -52.5, -51.5, -50.5,\n       -49.5, -48.5, -47.5, -46.5, -45.5, -44.5, -43.5, -42.5, -41.5, -40.5,\n       -39.5, -38.5, -37.5, -36.5, -35.5, -34.5, -33.5, -32.5, -31.5, -30.5,\n       -29.5, -28.5, -27.5, -26.5, -25.5, -24.5, -23.5, -22.5, -21.5, -20.5,\n       -19.5, -18.5, -17.5, -16.5, -15.5, -14.5, -13.5, -12.5, -11.5, -10.5,\n        -9.5,  -8.5,  -7.5,  -6.5,  -5.5,  -4.5,  -3.5,  -2.5,  -1.5,  -0.5,\n         0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n        10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5,  18.5,  19.5,\n        20.5,  21.5,  22.5,  23.5,  24.5,  25.5,  26.5,  27.5,  28.5,  29.5,\n        30.5,  31.5,  32.5,  33.5,  34.5,  35.5,  36.5,  37.5,  38.5,  39.5,\n        40.5,  41.5,  42.5,  43.5,  44.5,  45.5,  46.5,  47.5,  48.5,  49.5,\n        50.5,  51.5,  52.5,  53.5,  54.5,  55.5,  56.5,  57.5,  58.5,  59.5,\n        60.5,  61.5,  62.5,  63.5,  64.5,  65.5,  66.5,  67.5,  68.5,  69.5,\n        70.5,  71.5,  72.5,  73.5,  74.5,  75.5,  76.5,  77.5,  78.5,  79.5,\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5])lon(lon)float640.5 1.5 2.5 ... 357.5 358.5 359.5axis :Xbounds :lon_bndslong_name :longitudestandard_name :longitudeunits :degrees_eastarray([  0.5,   1.5,   2.5, ..., 357.5, 358.5, 359.5], shape=(360,))month(month)int641 2 3 4 5 6 7 8 9 10 11 12axis :Tbounds :time_bndsstandard_name :timetitle :timetype :doublearray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])Indexes: (3)latPandasIndexPandasIndex(Index([-89.5, -88.5, -87.5, -86.5, -85.5, -84.5, -83.5, -82.5, -81.5, -80.5,\n       ...\n        80.5,  81.5,  82.5,  83.5,  84.5,  85.5,  86.5,  87.5,  88.5,  89.5],\n      dtype='float64', name='lat', length=180))lonPandasIndexPandasIndex(Index([  0.5,   1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,\n       ...\n       350.5, 351.5, 352.5, 353.5, 354.5, 355.5, 356.5, 357.5, 358.5, 359.5],\n      dtype='float64', name='lon', length=360))monthPandasIndexPandasIndex(Index([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype='int64', name='month'))Attributes: (19)cell_measures :area: areacellocell_methods :area: mean where sea time: meancomment :Model data on the 1x1 grid includes values in all cells for which ocean cells on the native grid cover more than 52.5 percent of the 1x1 grid cell. This 52.5 percent cutoff was chosen to produce ocean surface area on the 1x1 grid as close as possible to ocean surface area on the native grid, while not introducing fractional cell coverage.description :This may differ from \"surface temperature\" in regions of sea ice or floating ice shelves. For models using conservative temperature as the prognostic field, they should report the top ocean layer as surface potential temperature, which is the same as surface in situ temperature.frequency :monid :toslong_name :Sea Surface TemperaturemipTable :Omonout_name :tosprov :Omon ((isd.003))realm :oceanstandard_name :sea_surface_temperaturetime :timetime_label :time-meantime_title :Temporal meantitle :Sea Surface Temperaturetype :realunits :degCvariable_id :tos\n\n\nFor every spatial coordinate (gridded cell center), we now have a monthly mean SST for the time period. So lets look a monthly mean off the coast of San Luis Obispo.\n\nfig, ax  = plt.subplots();\ngrouped_mean.sel(lon=238, lat=35.2289, method='nearest').plot();\nax.set_title('Monthly mean SST off the coast of SLO');\nax.set_xlabel('Month');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion???\n\n\n\nWhat are these trailing semicolons all about? Python does not typically end lines with a semicolon. Experiment with the above code block with and without the semicolons.\n\n\n\nfig, ax  = plt.subplots();\n(grouped_mean.sel(month=1) - grouped_mean.sel(month=7)).plot(ax=ax, robust=True)\nax.set_title('Mean January / July Temperature Difference');"
  },
  {
    "objectID": "python-pdal.html",
    "href": "python-pdal.html",
    "title": "",
    "section": "",
    "text": "Import the needed libraries.\n\nfrom io import BytesIO\nfrom joblib import Parallel, delayed\nfrom pathlib import Path\nfrom shapely import Polygon, Point\n\n\nimport geopandas as gpd\nimport numpy as np\nimport pdal\nimport requests\nimport zipfile\n\nIf you do not have the MS building footprint layer, run the following cell to download it. Change the save path as needed.\n\n# directory where you want the building GeoJSON extracted\nchange_this = '/home/michael/CP/UEFI/vectors'\nbuildings_path = Path(change_this)\nbuildings_path.mkdir(parents=True, exist_ok=True)\n\n# download\nurl = 'https://minedbuildings.z5.web.core.windows.net/legacy/usbuildings-v2/California.geojson.zip'\nresponse = requests.get(url, stream=True)\nresponse.raise_for_status()\n\n# unzip\nwith zipfile.ZipFile(BytesIO(response.content)) as z:\n    z.extractall(buildings_path)\n\nOpen the vector files.\n\n# paths\nbuildings_path = buildings_path / 'eaton_buildings.geojson'\n\naoi_path = '/home/michael/CP/UEFI/vectors/Eaton_Perimeter_20250121.geojson'\n\nlaz_dir = Path('/home/michael/CP/UEFI/small_laz')\n\n# read buildings\nbuildings = gpd.read_file(buildings_path)\naoi = gpd.read_file(aoi_path)\n\nChange the crs of both to UTM Z10. Then clip the buildings down tot he eaton footprint (with a 20 m buffer).\n\n# set crs to epsg:26910 (UTM 10) for vectors \nbuildings = buildings.to_crs(epsg=26910)\naoi = aoi.to_crs(epsg=26910)\n\n# clip building to AOI\nbuildings = gpd.clip(buildings, aoi.buffer(20))\n\n# make a column filled with 6\nbuildings['class'] = 6\n\nWe will use PDAL to read the points and reproject them. We will then grab the extent by finding the min and max points along each axis using numpy. Adjust you path.\n\ndef get_pc_and_extent(laz, srs):\n    '''\n    Reads and reprojects point cloud.\n    Returns points as np structured array and\n    extent as shapely Polygon.\n    '''\n\n    pipe = pdal.Reader.las(filename=laz).pipeline()\n    pipe |= pdal.Filter.reprojection(out_srs=f'EPSG:{srs}')\n    n = pipe.execute()\n    arr = pipe.arrays[0]\n\n    minx = np.min(arr[0]['X'])\n    maxx = np.max(arr[0]['X'])\n    miny = np.min(arr[0]['Y'])\n    maxy = np.max(arr[0]['Y'])\n\n    return arr, Polygon((\n        (minx, miny),\n        (minx, maxy),\n        (maxx, maxy),\n        (maxx, miny),\n        (minx, miny)\n    )) \n\n\ndef in_building(x, y, b_geoms):\n    '''returns a Bool mask, True if point is in building footprint'''\n    return b_geoms.contains(Point(x, y)).any()\n\n\n# find a file in dir\nfiles = laz_dir.glob('*.laz')\nlaz = next(files)\nbasename = laz.stem\n\n# get points and extent\npoints, extent = get_pc_and_extent(laz, buildings.crs.to_epsg())\n\n\n# clip the building to the extent\ntile_buildings = gpd.clip(buildings, extent)\ntile_path = laz_dir / f'{basename}.geojson'\ntile_buildings.to_file(tile_path, layer='data')\n\n\n# create stages and stage creator functions\ndef overlay_filter(buildings):\n    return pdal.Filter.overlay(\n        column='class',\n        datasource=buildings,\n        layer='data',\n        dimension='Classification'\n        )\n\n\nexpression = pdal.Filter.expression(expression='Classification != 6')\n\n\ndef writer(dst):\n    return pdal.Writer.las(\n        forward='all',\n        filename=dst\n        )\n\n\ndef pipeline(points, buildings, dst):\n    pipe = overlay_filter(buildings).pipeline(points)\n    pipe | expression\n    pipe | writer(dst)\n\n    return pipe\n\ndst = laz_dir /f'{basename}_no_buildings.laz'\npipe = pipeline(points, tile_path, dst)\nn = pipe.execute()"
  }
]